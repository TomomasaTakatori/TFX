{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFTを試す\n",
    "> このノートブックでは`estimator3_train_and_evaluate_(1).ipynb`で作成したEstiamtorにfeature engineeringを行う。 前処理としてはシンプルに特徴量のスケーリングのみをおこなう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFTについて　\n",
    "> TFTは、大きく分けて２つの段階にわかれる。 \n",
    "    1. Analyze phase\n",
    "    2. Transform phase  \n",
    "である\n",
    "\n",
    "### 実際の操作\n",
    "\n",
    "1. 訓練データセットのスキーマを定義\n",
    "2. 分析してから変換を行うPTransformを利用して、前処理済みのデータと変換関数を返す\n",
    "    1. Beamの関数でデータを読み込む\n",
    "    2. 訓練に必要ないデータをフィルターする\n",
    "    3. 生データと定義したデータのスキーマを含むメタデータを`AnalyzeAndTransformDataset(preprocess func)`で処理する\n",
    "3. 前処理済み訓練データをTFRecordsとして書き出す\n",
    " \n",
    "`注意点` : preprocess func は、 TensorFlow（Transform）の関数で書く必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実際に書いてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import os.path\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "\n",
    "from apache_beam.io import tfrecordio\n",
    "from tensorflow_transform.coders import ExampleProtoCoder\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### まず、metadataを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_NAMES = ['pickuplon','pickuplat', 'dropofflon','dropofflat','passengers']\n",
    "TARGET_FEATURE_NAME = 'fare_amount'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "def create_raw_metadata():  \n",
    "    \n",
    "    raw_data_schema = {}\n",
    "    \n",
    "    # key feature schema\n",
    "    raw_data_schema[KEY_COLUMN]= dataset_schema.ColumnSchema(\n",
    "        tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "    \n",
    "    # target feature schema\n",
    "    raw_data_schema[TARGET_FEATURE_NAME]= dataset_schema.ColumnSchema(\n",
    "        tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "        \n",
    "    # numerical features schema\n",
    "    raw_data_schema.update({ column_name : dataset_schema.ColumnSchema(\n",
    "        tf.float32, [], dataset_schema.FixedColumnRepresentation())\n",
    "                            for column_name in NUMERIC_FEATURE_NAMES})\n",
    "    \n",
    "      # create dataset_metadata given raw_schema\n",
    "    raw_metadata = dataset_metadata.DatasetMetadata(\n",
    "        dataset_schema.Schema(raw_data_schema))\n",
    "    \n",
    "    return raw_metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ｃｓｖから読み込む事もできる。（この場合一行目がカラム名でないのでexplicitに入力する必要がある）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ｃｓｖから読み込む事もできる。（この場合一行目がカラム名でないのでexplicitに入力する必要がある）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下記でも良い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUMERIC_FEATURE_NAMES = ['pickuplon','pickuplat', 'dropofflon','dropofflat','passengers']\n",
    "TARGET_FEATURE_NAME = 'fare_amount'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "def create_raw_metadata():  \n",
    "    \n",
    "    raw_data_schema = {}\n",
    "    \n",
    "    # key feature schema\n",
    "    raw_data_schema[KEY_COLUMN] = tf.FixedLenFeature([], tf.float32)\n",
    "    \n",
    "    # target feature schema\n",
    "    raw_data_schema[TARGET_FEATURE_NAME]= tf.FixedLenFeature([], tf.float32)\n",
    "        \n",
    "    # numerical features schema\n",
    "    raw_data_schema.update({ column_name :tf.FixedLenFeature([], tf.float32)\n",
    "                            for column_name in NUMERIC_FEATURE_NAMES})\n",
    "    \n",
    "      # create dataset_metadata given raw_schema\n",
    "    raw_metadata = dataset_metadata.DatasetMetadata(\n",
    "        dataset_schema.from_feature_spec(raw_data_schema))\n",
    "    \n",
    "    return raw_metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 14:06:32.122081 4459820480 deprecation.py:323] From <ipython-input-15-a953fbc5c3e9>:11: ColumnSchema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "ColumnSchema is a deprecated, use from_feature_spec to create a `Schema`\n",
      "W0806 14:06:32.171721 4459820480 deprecation_wrapper.py:119] From /Users/baito/Works/TFX/.venv/lib/python3.7/site-packages/tensorflow_transform/tf_metadata/dataset_schema.py:107: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0806 14:06:32.184382 4459820480 deprecation_wrapper.py:119] From /Users/baito/Works/TFX/.venv/lib/python3.7/site-packages/tensorflow_transform/tf_metadata/schema_utils.py:63: The name tf.SparseFeature is deprecated. Please use tf.io.SparseFeature instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_schema': Schema(feature {\n",
       "  name: \"dropofflat\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"dropofflon\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"fare_amount\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"key\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"passengers\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"pickuplat\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"pickuplon\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "  }\n",
       "  shape {\n",
       "  }\n",
       "}\n",
       ")}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_raw_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing fnを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "    # 他の特徴料は変化させないまま、いくつかの特徴量を修正する可能性があるため、最初にコピーしておく。\n",
    "    outputs = inputs.copy()\n",
    "    \n",
    "    # bucketize\n",
    "    outputs['pickuplon'] = tft.bucketize(inputs['pickuplon'], num_buckets=5)\n",
    "    outputs['pickuplat'] = tft.bucketize(inputs['pickuplat'], num_buckets=5)\n",
    "    outputs['dropofflon'] = tft.bucketize(inputs['dropofflon'], num_buckets=5)\n",
    "    outputs['dropofflat'] = tft.bucketize(inputs['dropofflat'], num_buckets=5)\n",
    "    \n",
    "    # Scaling\n",
    "    outputs['passengers'] = tft.scale_to_0_1(inputs['passengers'])\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### beamの関数を書く\n",
    "> 通常のbeam処理内にTFTの処理をラッピングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 14:07:44.162734 4459820480 tfrecordio.py:57] Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with beam.Pipeline() as p: # 必要ならパイプラインオプションを書いておく\n",
    "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "        # Csv coder\n",
    "        ordered_columns = [\n",
    "            'fare_amount', 'pickuplon','pickuplat','dropofflon',\n",
    "            'dropofflat','passengers', 'key'\n",
    "        ]\n",
    "        raw_metadata = create_raw_metadata()\n",
    "        converter = tft.coders.CsvCoder(ordered_columns, raw_metadata.schema)\n",
    "        \n",
    "        # 訓練データ読み込み\n",
    "        raw_data = (\n",
    "            p\n",
    "            | \"ReadTrainData\" >> beam.io.ReadFromText('./data/taxi-train.csv')\n",
    "            | \"DecodeTrainCsv\" >> beam.Map(converter.decode)\n",
    "        )\n",
    "        raw_dataset = (raw_data, raw_metadata)\n",
    "        \n",
    "        ## 前処理関数を当てはめるn\n",
    "        transformed_dataset, transform_fn = (\n",
    "            raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)\n",
    "        )\n",
    "        transformed_data, transformed_metadata = transformed_dataset\n",
    "        \n",
    "        ## 前処理済み訓練データをTFRecordで保存\n",
    "        transformed_data_coder = ExampleProtoCoder(transformed_metadata.schema)\n",
    "        _ = (\n",
    "            transformed_data\n",
    "            | \"EncodeTrainData\" >> beam.Map(transformed_data_coder.encode)\n",
    "            | \"WriteTrainData\" >> beam.io.WriteToTFRecord(\n",
    "                './tfrecord/train_transformed'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # テストデータを読み込み\n",
    "        raw_test_data = (\n",
    "            p\n",
    "            | \"ReadTestData\" >> beam.io.ReadFromText('./data/taxi-test.csv')\n",
    "            | \"DecodeTestCsv\" >> beam.Map(converter.decode)\n",
    "        )\n",
    "        raw_test_dataset = (raw_test_data, raw_metadata)\n",
    "        \n",
    "        ## 前処理関数を当てはめる\n",
    "        transformed_test_dataset = (\n",
    "            (raw_test_dataset, transform_fn) | tft_beam.TransformDataset()\n",
    "        )\n",
    "        transform_test_data, _ = transformed_test_dataset\n",
    "        \n",
    "        ## 前処理済み訓練データをTFRecordで保存\n",
    "        _ = (\n",
    "            transform_test_data\n",
    "            | \"EncodeTestData\" >> beam.Map(transformed_data_coder.encode)\n",
    "            | \"WriteTestData\" >> beam.io.WriteToTFRecord('./tfrecord/test_transformed')\n",
    "        )\n",
    "        \n",
    "        # 変換関数を保存\n",
    "        _ = (\n",
    "            transform_fn\n",
    "            | \"WriteTransformFn\" >> tft_beam.WriteTransformFn(\"./transform_fn\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 変換されたTFRecordを読み込んでチェックする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(example_proto):\n",
    "    features={name : tf.FixedLenFeature([], tf.float32) for name in [\n",
    "            'fare_amount','passengers', 'key'\n",
    "        ]}\n",
    "    features.update({\n",
    "        name: tf.FixedLenFeature([], tf.int64) for name in [\n",
    "            'pickuplon','pickuplat','dropofflon',\n",
    "            'dropofflat']\n",
    "    })\n",
    "    parsed_features = tf.parse_single_example(example_proto, features)\n",
    "    return parsed_features\n",
    "\n",
    "dataset = tf.data.TFRecordDataset(['./tfrecord/train_transformed-00000-of-00001'])\n",
    "dataset = dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropofflat': 4, 'dropofflon': 3, 'fare_amount': 12.0, 'key': 0.0, 'passengers': 0.0, 'pickuplat': 2, 'pickuplon': 1}\n",
      "{'dropofflat': 4, 'dropofflon': 4, 'fare_amount': 4.5, 'key': 1.0, 'passengers': 0.0, 'pickuplat': 4, 'pickuplon': 4}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "問題ない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_eval_columns(transformed_metadata):\n",
    "    feature_columns = []\n",
    "    \n",
    "    column_schemas = transformed_metadata.schema.as_feature_spec()\n",
    "    \n",
    "    for feature_name in column_schemas:\n",
    "        column_schema = column_schemas[feature_name]\n",
    "        \n",
    "        if column_schema.dtype == tf.float32:\n",
    "            feature_columns.append(tf.feature_column.numeric_column(feature_name))\n",
    "        elif column_schema.dtype == tf.int64:\n",
    "            feature_columns.append(\n",
    "                tf.feature_column.categorical_column_with_identity(\n",
    "                feature_name, num_buckets=5+1)\n",
    "                                  )\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_func2(example_proto):\n",
    "    feat_eval_col = create_feature_eval_columns(transformed_metadata)\n",
    "    feature_spec =  tf.feature_column.make_parse_example_spec(\n",
    "      feat_eval_col)\n",
    "    features = tf.io.parse_single_example(example_proto, feature_spec)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import metadata_io\n",
    "TRANSFORM_ARTEFACTS_DIR = 'transform_fn'\n",
    "transformed_metadata = metadata_io.read_metadata(\n",
    "        os.path.join(TRANSFORM_ARTEFACTS_DIR,\"transformed_metadata\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(['./tfrecord/train_transformed-00000-of-00001'])\n",
    "dataset = dataset.map(_parse_func2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropofflat': SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1])), 'dropofflon': SparseTensorValue(indices=array([[0]]), values=array([3]), dense_shape=array([1])), 'pickuplat': SparseTensorValue(indices=array([[0]]), values=array([2]), dense_shape=array([1])), 'pickuplon': SparseTensorValue(indices=array([[0]]), values=array([1]), dense_shape=array([1])), 'fare_amount': array([12.], dtype=float32), 'key': array([0.], dtype=float32), 'passengers': array([0.], dtype=float32)}\n",
      "{'dropofflat': SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1])), 'dropofflon': SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1])), 'pickuplat': SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1])), 'pickuplon': SparseTensorValue(indices=array([[0]]), values=array([4]), dense_shape=array([1])), 'fare_amount': array([4.5], dtype=float32), 'key': array([1.], dtype=float32), 'passengers': array([0.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(next_element))\n",
    "    print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
